{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89b62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (0.3.26)\n",
      "Requirement already satisfied: faiss-cpu in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: openai in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (1.91.0)\n",
      "Requirement already satisfied: tiktoken in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: pypdf in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (3.17.4)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain) (0.3.66)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain) (0.4.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from openai) (4.13.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain faiss-cpu openai tiktoken pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620b9454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载完成，共 418 段\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "docs_path = './input'\n",
    "all_docs = []\n",
    "\n",
    "for file in os.listdir(docs_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(os.path.join(docs_path, file))\n",
    "        pages = loader.load()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        docs = splitter.split_documents(pages)\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "print(f\"Loading completed, total {len(all_docs)} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd0a1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/vxf45hss6vv4b_t4xkxhkm240000gn/T/ipykernel_47170/960842804.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/Users/xujing/miniconda3/envs/py3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(all_docs, embedding_model)\n",
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb9d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/vxf45hss6vv4b_t4xkxhkm240000gn/T/ipykernel_47170/664163176.py:4: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"deepseek-r1:8b\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "llm = Ollama(model=\"deepseek-r1:8b\")\n",
    "\n",
    "# Multi-perspective question generation + multi-round retrieval\n",
    "multi_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 4}),\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825d0e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/vxf45hss6vv4b_t4xkxhkm240000gn/T/ipykernel_47170/4291094833.py:10: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 回答：\n",
      "<think>\n",
      "好的，我现在需要回答用户的问题：“论文中提到了哪些深度学习方法？”首先，我得仔细看一下提供的上下文内容。\n",
      "\n",
      "论文中提到的模型部分主要是CSP（Center-Part Suppression），这是他们提出的方法。接着看到对比的是Fr-RCNN*、MS-CNN和他们的基线模型。这些应该都是相关的检测或识别方法。另外，在技术细节里提到了R-FoCN，可能是指R-FCN的一种变体或者相关工作，比如使用多尺度特征融合的结构。\n",
      "\n",
      "在训练部分提到的深度学习组件包括ResNet（他们用的是ResNet-50），以及各种归一化层如BN、IN和LN。还有激活函数ReLU，损失函数是Smooth L1 Loss，并调整了超参数r值。提出的ACSP方法结合了BN、IN和LN，各占一定比例。\n",
      "\n",
      "然后在相关的研究工作中引用了很多论文的方法，比如RCNN系列（Faster RCNN, R-FCN）、SSD、YOLO等传统CNN检测器，还有Cityscapes数据集处理中的多尺度特征融合策略。这里需要注意用户的问题可能不仅限于他们自己的方法，而是整个文献中提到的所有深度学习技术。\n",
      "\n",
      "总结一下，主要的方法包括CSP及其变体（如ACSP），对比的模型有Fr-RCNN、MS-CNN和基线Faster R-CNN，并提到了R-FoCN作为他们的改进基础。归一化层方面涉及Batch Normalization, Instance Normalization, Layer Normalization等。多尺度特征融合参考了CSP的工作，但可能在其他部分也有应用。此外，在讨论相关工作时提到的还有各种经典的CNN检测方法如Faster R-CNN、R-FCN、SSD、YOLO，以及语义分割和边缘检测相关的模型。\n",
      "\n",
      "需要确保没有遗漏任何明显的方法名称，并且正确解释每个术语的关系。例如，“conv4 3”可能属于CSP或他们的基线部分，而提出的ACSP方法应该包括多层卷积等操作来融合不同归一化层的结果。\n",
      "</think>\n",
      "根据提供的论文摘要和上下文信息：\n",
      "\n",
      "1. **Fr-RCNN** (Region-based Faster R-CNN)：用于目标检测的基准模型之一，具有两阶段处理流程（RPN 和 FRCNN）。\n",
      "\n",
      "2. **MS-CNN** (Multi-Scale CNN)：另一个用于目标检测的模型，专注于多尺度特征融合。\n",
      "\n",
      "3. **CSP** (Center-Part Suppression)：论文中的核心方法，结合了多种归一化层来加速训练并提升性能。它参考了原始的 Faster R-CNN 框架，并提到“body network”为 VGG-16 网络（一种经典的 CNN 架构）。\n",
      "\n",
      "4. **R-FoCN** (可能指 R-FoCN)：在上下文中提到了 CFN (Convolutional Feature Network)，这是一种用于多尺度特征融合的模型，作者在此基础上进行了改进。CSP 的技术中也涉及了类似的思想，并提出了 ACSP（Aggregated Center-Part Suppression and Position）作为其变体。\n",
      "\n",
      "4. **R-FoCN**：可能是指他们提出的增强版 Faster R-CNN 模型，结合了 CFN 和 CSP 的多尺度特征融合结构。具体来说，它包含一个 side branch 用于生成侧向激活图，并与原始的 conv4_3 特征图进行合并。\n",
      "\n",
      "5. **Batch Normalization (BN)**：论文中提到使用 BN、IN 和 LN 进行归一化处理的不同组合比例（来自 Figure 3）。\n",
      "\n",
      "6. **Instance Normalization** (IN) 和 **Layer Normalization** (LN)：用于归一化的技术，分别作为 IN Mean/LN Mean/IN Variance/LN Variance 等提到的组成部分。\n",
      "\n",
      "7. **Smooth L1 Loss**：论文中调整了损失函数中的超参数 r 值，并提到了使用 Smooth L1 Loss 优化训练过程。\n",
      "\n",
      "8. **ResNet-50** (Residual Network)：用于目标检测的预训练模型，属于 Faster R-CNN 的一部分或者作为其他方法的基础网络（如 Region Proposal Network）。\n",
      "\n",
      "9. **VGG-16**：初始化权重来自 VGG-16 网络，在实验部分提到其激活图提取层（conv4_3）。\n",
      "\n",
      "📚 来源：\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 4\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 17\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 0\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 8\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 4\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 9\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 3\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 19\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 3\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 3\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 4\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 8\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 12\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 8\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 2\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 6\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 0\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 3\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 4\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 1\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 6\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 5\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 11\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 1\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 6\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 5\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 12\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 3\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=multi_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"What deep learning methods are mentioned in the papers?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"🧠 Answer:\")\n",
    "print(result[\"result\"])\n",
    "print(\"\\n📚 Sources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- Filename: {doc.metadata.get('source', 'Unknown')}  | Page: {doc.metadata.get('page', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ee7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 回答：\n",
      "<think>\n",
      "嗯，用户让我总结一篇名为“CSP”的论文的main contributions部分。首先需要仔细阅读提供的上下文材料，找出关键信息。\n",
      "\n",
      "看到了很多关于行人检测的数据表、实验设置和讨论段落，里面提到了一些技术细节比如分辨率调整、不同归一化方法的影响等，但没有直接提到标题或具体论文名称。不过用户的问题中提到了“CCHI”这篇论文，我需要确认上下文是否与之对应。\n",
      "\n",
      "从内容来看，表格显示了行人检测的mAP和FPS数据比较，特别是他们提出的方法在不同分辨率下表现良好，尤其是在640×1280时达到最佳性能。还讨论了使用Switchable Normalization (SN)提升收敛性和稳定性，以及提到不需要预定义先验框就能处理高纵横比的目标。\n",
      "\n",
      "这些点确实体现了该方法的创新性：通过调整输入分辨率解决了关键问题；引入自适应归一化策略增强了网络对不同特征尺度的适应能力；不依赖于anchor-based机制提高了泛化性。实验结果也显示了在CityPersons和COCO数据集上的优势，特别是在高纵横比目标检测方面。\n",
      "\n",
      "需要确认这些信息是否准确对应到用户提到的“CCHI”论文的核心贡献上，并检查是否有其他相关点被遗漏或强调。此外要注意表格中的比较对象如Fr-RCNN、MS-CNN和他们的基线方法，以及对现有方法（如TLL）的对比分析。\n",
      "</think>\n",
      "根据提供的上下文内容，可以总结出 CCHI 论文的主要贡献和创新点如下：\n",
      "\n",
      "1. **输入分辨率的重要性**：作者通过实验发现，在行人检测中使用特定的输入分辨率（例如 640×1280）能够显著提升模型性能。他们的方法在该分辨率下表现最佳，并且比原始分辨率有更好的收敛性。\n",
      "   \n",
      "2. **自适应归一化策略 (Switchable Normalization)**：他们提出了一种新的归一化方法，称为 Switchable Normalization (SN)，通过动态调整不同层使用哪种归一化方式（包括 BatchNorm、InstanceNorm 和 LayerNorm）来提升模型的性能。实验表明 SN 比单一的 BN 或 LN 方法更有效。\n",
      "\n",
      "3. **无需先验框**：他们提出的方法不需要像传统 anchor-based 方法那样依赖预定义的边界框，这使得其具有更强的泛化能力，并且在高纵横比目标检测方面表现更好。\n",
      "4. **高效的多尺度特征融合机制 (CSP)**：\n",
      "   - 作者设计了一种高效的通道级全局信息交互结构 CSP（Cross Stage Partial），该方法通过特定的方式进行特征融合，在保持计算效率的同时提升了整体性能。\n",
      "\n",
      "5. **实验验证**：他们在多个数据集上进行了广泛的实验，包括 Caltech 和 COCO 数据集，并与多种现有先进算法进行了比较，证明了其方法在准确性和速度上的优越性。\n",
      "6. **解决负样本问题**：\n",
      "   - 作者针对行人检测中常见的背景干扰和尺度变化问题提出了改进策略。\n",
      "\n",
      "这些贡献共同推动了计算机视觉领域目标检测技术的发展。\n",
      "\n",
      "📚 来源：\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 4\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 17\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 0\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 8\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 18\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 12\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 4\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 19\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 4\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 8\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 4\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 3\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 7\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 0\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 17\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 19\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 9\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 2\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 4\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 2\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 4\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 7\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 8\n"
     ]
    }
   ],
   "source": [
    "query = \"Please summarize the main contributions and innovations of the CCHI paper?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"🧠 Answer:\")\n",
    "print(result[\"result\"])\n",
    "print(\"\\n📚 Sources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- Filename: {doc.metadata.get('source', 'Unknown')}  | Page: {doc.metadata.get('page', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cadb211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 回答：\n",
      "The paper mentions several deep learning methods:\n",
      "\n",
      "1. R-FCN (Region-based Fully Convolutional Networks)\n",
      "2. YOLO V3\n",
      "3. CSP (Class-Specific Pixel Loss) for pedestrian detection\n",
      "4. SN (Scale Normalization) for normalization\n",
      "5. BN (Batch Normalization) for normalization\n",
      "6. LN (Layer Normalization) for normalization\n",
      "\n",
      "Note that some of these methods are mentioned as being compared or contrasted with others, rather than being the primary focus of the paper.\n",
      "\n",
      "📚 来源：\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 4\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 17\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 0\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 8\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 4\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 4\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 3\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 0\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 4\n",
      "- 文件名: ./input/CCHI.pdf  | 页码: 3\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 4\n",
      "- 文件名: ./input/Mao_What_Can_Help_CVPR_2017_paper.pdf  | 页码: 9\n",
      "- 文件名: ./input/ACSP.pdf  | 页码: 8\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 8\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 19\n",
      "- 文件名: ./input/2019 cvpr CSP.pdf  | 页码: 12\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.2:latest\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=multi_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"What deep learning methods are mentioned in the papers?\"\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"🧠 Answer:\")\n",
    "print(result[\"result\"])\n",
    "print(\"\\n📚 Sources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- Filename: {doc.metadata.get('source', 'Unknown')}  | Page: {doc.metadata.get('page', 'Unknown')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
